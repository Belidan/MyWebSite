<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Dimitrij-Marian Holm</title>
    <link>//localhost:1313/projects/</link>
    <description>Recent content in Projects on Dimitrij-Marian Holm</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 01 Feb 2018 21:28:43 -0500</lastBuildDate>
    
	<atom:link href="//localhost:1313/projects/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Master Thesis: A Robot System for Object Reconstruction</title>
      <link>//localhost:1313/projects/masterthesis/</link>
      <pubDate>Thu, 01 Feb 2018 21:28:43 -0500</pubDate>
      
      <guid>//localhost:1313/projects/masterthesis/</guid>
      <description>This master thesis exmpands the related work of my last project (Self learning Pipeline) with the ability for grasp pose detection and manipulation of the environment. Object recognition is one of the major topics in developing intelligent autonomous systems. But to develop a fully autonomous system which is able to gain information about the environment including interaction within, a lot of additional tasks are required such as processing of the sensor inputs leading to a representation of different objects which is needed for object recognition.</description>
    </item>
    
    <item>
      <title>Research Project: Self-learning Pipeline for 3D objects</title>
      <link>//localhost:1313/projects/slp/</link>
      <pubDate>Thu, 01 Feb 2018 21:28:43 -0500</pubDate>
      
      <guid>//localhost:1313/projects/slp/</guid>
      <description>The focus of this research project was object recognition in autonomous systems. After study the research and adjacent fields of object recognition my focus was to develop an automated process for 3D object generation with the goal to create to a curious robot. The resulst is the Self Learning Pipeline (SLP). The pipeline contains the steps from extracing possible objects parts from a raw point cloud as input, select and track one object, get different views of the tracked object, registrate these object parts to a whole point cloud representing an object and finally the synthesis to a full 3D mesh which can be used for object recogintion or every other task with the need of 3D models.</description>
    </item>
    
    <item>
      <title>Research Project: SLAM in dynamic Environments</title>
      <link>//localhost:1313/projects/slam/</link>
      <pubDate>Tue, 31 Oct 2017 21:28:43 -0500</pubDate>
      
      <guid>//localhost:1313/projects/slam/</guid>
      <description>As simultaneous location and mapping (SLAM) is one of the key features for autonomous systems to navigate within the environment, at lot of progress have been accieved in the last years. If the environment is not changing the accuracy for SLAM is quite good, as the map is created once it should not be updated later. But the world is not static, it is changing over time. My research project accieved an approach to challenge with a changing world.</description>
    </item>
    
    <item>
      <title>Bachelor Thesis: Concept of visualization of 3D-Data</title>
      <link>//localhost:1313/projects/bachelorthesis/</link>
      <pubDate>Sat, 01 Feb 2014 21:28:43 -0500</pubDate>
      
      <guid>//localhost:1313/projects/bachelorthesis/</guid>
      <description>In the industrial sector of composite materials there are no measurement systems which allow combining and visualizing a set of 3D scan data with 2D pictures. The aim of this thesis is to develop software that can fill this gap. The program allows the user to texture 3D models with the fitting set of picture informations. Windows WPF was used as a framework. It provides the possibility of model generating. As a part task a human machine interface for interacting is under development.</description>
    </item>
    
    <item>
      <title>Intership: Development of a GUI for engine test benches</title>
      <link>//localhost:1313/projects/quintenz/</link>
      <pubDate>Sat, 01 Feb 2014 21:28:43 -0500</pubDate>
      
      <guid>//localhost:1313/projects/quintenz/</guid>
      <description>For this intership i developed a graphical user interface for steering electrical engine test benches and monitor the behaviour of the engine. This includes the interface between Desktop and the test bench.
Trained Skills - Programm language C++ - Development with Microsoft CLI/C++ - GUI-Design with consideration of medical standards 
Due to its protection level a download of the document is not available.</description>
    </item>
    
    <item>
      <title>Student Project: Puzzle Solver</title>
      <link>//localhost:1313/projects/puzzlesolver/</link>
      <pubDate>Sat, 01 Feb 2014 21:28:43 -0500</pubDate>
      
      <guid>//localhost:1313/projects/puzzlesolver/</guid>
      <description>For this student project we developed a puzzle solver. The input were some pictures with several, different pieces of the puzzle. The single pieces were extracted from the picture. With information about the geometric and color characterstics of the endges the coherent pieces were calculated. With the calculated result the output of the puzzle solver was a 3D animation in which the random placed single puzzle pieces flew to their destination.</description>
    </item>
    
    <item>
      <title>Student Project: Acoustic Camera</title>
      <link>//localhost:1313/projects/acousticcamera/</link>
      <pubDate>Tue, 01 Feb 2000 21:28:43 -0500</pubDate>
      
      <guid>//localhost:1313/projects/acousticcamera/</guid>
      <description>As an student project we developed an acoustic camera. A matrix made out of microphones the acoustic signals were cought. The runtime of the sonic wave between the microphones was used to estimate the direction of the sound source. It was calculated on an FPGA. Via an USP-Port the results were sent to the PC and shown on an refreshing image. My part was to designing the protocoll between PC and FPGA, develop the interface for the visual output program as well as implementing the necessary communication software (steer/control data flow FPGA&amp;lt;-&amp;gt;PC, transmitting processed data to visual output).</description>
    </item>
    
  </channel>
</rss>